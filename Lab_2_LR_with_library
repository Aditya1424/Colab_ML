import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

X=[171,151,124,134,156]
y=[80,60,45,50,65]

def findCoeff(X,y):
    X_mean=np.mean(X)
    y_mean=np.mean(y)
    den=0
    num=0
    for i in range(len(X)):
        num+=((X[i]-X_mean)*(y[i]-y_mean))
        den+=(X[i]-X_mean)**2
    m=num/den
    c=y_mean-(m*X_mean)
    return m,c

m,c=findCoeff(X,y)
print(m,c)

height=130
predicted=height*m+c
print(predicted)

def plot_line(X,y,m,c):   
    max_X=np.max(X)+100  
    min_X=np.min(X)-100
    X_plot=np.linspace(min_X,max_X,100)
    y_predicted=m*X_plot+np.repeat(c,100)
    plt.scatter(X,y,color="blue",label="Scatter Points")
    plt.plot(X_plot,y_predicted,color="red",label="Simple Linear Regression")
    plt.legend()
    plt.show()
plot_line(X,y,m,c)

data=pd.read_csv('..\Dataset\headbrain.csv')
X2=data['Head Size(cm^3)'].values
y2=data['Brain Weight(grams)'].values
m,c=findCoeff(X2,y2)
plot_line(X2,y2,m,c)

rmse=0
for i in range(len(X2)):
    y_pred=c+m*X2[i]
    rmse+=((y2[i]-y_pred)**2)
rmse=np.sqrt(rmse/len(X2))
print(rmse)

### Linear Regression using SKLearn

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
data=pd.read_csv('..\Dataset\headbrain.csv')
X2=data['Head Size(cm^3)'].values
m=len(X2)
X2=X2.reshape((m,1))
y2=data['Brain Weight(grams)'].values

#Model Initialisation
reg=LinearRegression()
#Data Fitting
reg=reg.fit(X2,y2)
#Y Prediction
y_pred=reg.predict(X2)

print(reg.intercept_)
print(reg.coef_)

#Model Evaluation
rmse=np.sqrt(mean_squared_error(y2,y_pred))
r2=reg.score(X2,y2)
print(rmse)
print(r2)

data2=pd.read_csv('../dataset/FuelConsumption.csv')
data2.head(20)
X3=data2[["ENGINESIZE","FUELCONSUMPTION_CITY"]].values
y3=data2["CO2EMISSIONS"].values

#Model Initialisation
reg=LinearRegression()
#Data Fitting
reg=reg.fit(X3,y3)
#Y Prediction
y_pred=reg.predict(X3)
print(reg.intercept_)
print(reg.coef_)

#Model Evaluation
rmse=np.sqrt(mean_squared_error(y3,y_pred))
r2=reg.score(X3,y3)
print(rmse)
print(r2)

def plot_line2(X,y,m,c):   
    max_X1=np.max(X[0])
    min_X1=np.min(X[0])-10
    max_X2=np.max(X[1])
    min_X2=np.min(X[1])-10
    X_plot1=np.linspace(min_X1,max_X1,100)
    X_plot2=np.linspace(min_X2,max_X2,100)
#     X_plot3=np.linspace(min_X,max_X,100)
    y_predicted=m[0]*X_plot1+m[1]*X_plot2+np.repeat(c,100)
    print(y_predicted.shape)
#     plt.scatter(X[0],y,color="blue",label="Scatter Points")
#     plt.scatter(X[1],y,color="green",label="Scatter Points")
#     plt.plot(X_plot1,X_plot2,y_predicted,color="red",label="Simple Linear Regression")
    fig = plt.figure()

# Add an axes
    ax = fig.add_subplot(111,projection='3d')

# plot the surface
    ax.plot_surface(X_plot1, X_plot2, y_predicted, alpha=0.2)
#     img=plt.figure().add_subplot(111,projection='3d')
#     img.plot_surface(X_plot1,X_plot2,y_predicted,color='red',label="Multiple Linear Regression")
#     img.scatter3D(X[0],X[1],y,color='blue',label="Scatter Points")
#     plt.legend()
    plt.show()


# def find_eq(X,coef,inter):
#     n=len(X)
#     ans=inter
#     for i in range(n):
#         ans=ans+(X[i]*coef[i])
# def plot_line2(X,y,m,c):   
#     max_X=np.max(X)+100  
#     min_X=np.min(X)-100
#     X_plot=np.linspace(min_X,max_X,100)
#     y_predicted=m*X_plot+np.repeat(c,100)
#     plt.scatter(X[0],y,color="blue",label="Scatter Points")
#     plt.scatter(X[1],y,color="green",label="Scatter Points")
#     plt.plot(X_plot,y_predicted,color="red",label="Simple Linear Regression")
#     plt.legend()
#     plt.show()

X3=X3.reshape(2,1067)
plot_line2(X3,y3,reg.coef_,reg.intercept_)
